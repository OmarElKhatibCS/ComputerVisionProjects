{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "width,height = img.shape[:2]\n",
    "\n",
    "quarter_width , quarter_height = width/4 , height/4\n",
    "\n",
    "T = np.float32([ [1,0,quarter_width],[0,1,quarter_height] ])\n",
    "\n",
    "img_tran = cv2.warpAffine(img , T , (width,height))\n",
    "\n",
    "cv2.imshow('translated',img_tran)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "width,height = img.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2),90,1)\n",
    "\n",
    "img_rotation = cv2.warpAffine(img , rotation_matrix , (width,height))\n",
    "\n",
    "cv2.imshow('translated',img_rotation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resize / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "width , height = img.shape[:2]\n",
    "\n",
    "scaled_img = cv2.resize(img,None,fx = 0.75 , fy = 0.75,interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('scaled img 1 ',scaled_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "\n",
    "pyr_img = cv2.pyrDown(img)\n",
    "pyr_imgBack = cv2.pyrUp(pyr_img)\n",
    "\n",
    "cv2.imshow('Original Img ',img)\n",
    "cv2.imshow('Pyramid Img ',pyr_img)\n",
    "cv2.imshow('Pyramid Img Back',pyr_imgBack)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "\n",
    "start_row,end_row = int(width*.25),int(height*.75)\n",
    "start_col,end_col = int(width*.25),int(height*.75)\n",
    "\n",
    "cropped_img = img[start_row:end_row , start_col:end_col]\n",
    "\n",
    "cv2.imshow('Original Img ',img)\n",
    "cv2.imshow('Cropped Img ',cropped_img)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "cv2.imshow('Original Img ',img)\n",
    "\n",
    "matrix = np.ones(img.shape , dtype=\"uint8\")*75\n",
    "\n",
    "add_img = cv2.add(img,matrix)\n",
    "cv2.imshow('Add Img ',add_img)\n",
    "\n",
    "sub_img = cv2.subtract(img,matrix)\n",
    "cv2.imshow('Substracted Img ',sub_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitwise Opertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "rect = np.zeros((300,300),np.uint8)\n",
    "cv2.rectangle(rect,(50,60),(250,250),255,-1)\n",
    "cv2.imshow('rectangle ',rect)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "circle = np.zeros((300,300),np.uint8)\n",
    "cv2.circle(circle,(150,150),100,255,-1)\n",
    "cv2.imshow('circle ',circle)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "and_img = cv2.bitwise_and(circle,rect)\n",
    "or_img = cv2.bitwise_or(circle,rect)\n",
    "xor_img = cv2.bitwise_xor(circle,rect)\n",
    "notCircle_img = cv2.bitwise_not(circle)\n",
    "notRect_img = cv2.bitwise_not(rect)\n",
    "\n",
    "cv2.imshow(\"And\",and_img)\n",
    "cv2.imshow(\"Or\",or_img)\n",
    "cv2.imshow(\"Xor\",xor_img)\n",
    "cv2.imshow(\"NotCircle\",notCircle_img)\n",
    "cv2.imshow(\"NotRectangle\",notRect_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Bluring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input.jpg')\n",
    "img = img[50:250,50:250]\n",
    "kernel_10x10 =np.ones((10,10),np.float32)/100\n",
    "\n",
    "blurred = cv2.filter2D(img,-1,kernel_10x10)\n",
    "\n",
    "cv2.imshow('Blurred !!',blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input___.jpg')\n",
    "#img = img[150:500,150:500]\n",
    "#B,G,R = cv2.split(img)\n",
    "#img = cv2.merge([B,G,R])\n",
    "img = cv2.resize(img,None,fx=0.5,fy=0.5)\n",
    "cv2.imshow('Original',img)\n",
    "\n",
    "blur = cv2.blur(img,(3,3))\n",
    "cv2.imshow('Blurred !!',blur)\n",
    "\n",
    "Gblur = cv2.GaussianBlur(img,(7,7) ,0)\n",
    "cv2.imshow('Gaussian Blur !!',Gblur)\n",
    "\n",
    "median = cv2.medianBlur(img,5)\n",
    "cv2.imshow('median !!',median)\n",
    "\n",
    "bilateral = cv2.bilateralFilter(img,9,75,75)\n",
    "cv2.imshow('Blurred !!',bilateral)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image De-noising "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input____.jpg')\n",
    "cv2.imshow('Original',img)\n",
    "dst = cv2.fastNlMeansDenoisingColored(img,None,6,6,7,21)\n",
    "cv2.imshow('De noising',dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input____.jpg')\n",
    "cv2.imshow('Original',img)\n",
    "\n",
    "sharpening_kernel = np.array([  [-1,-1,-1] ,\n",
    "                                [-1,9,-1] ,\n",
    "                                [-1,-1,-1]\n",
    "                             ])\n",
    "sharpned = cv2.filter2D(img,-1,sharpening_kernel)\n",
    "cv2.imshow('sharpned',sharpned)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding , Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input____.jpg',0)\n",
    "cv2.imshow('Original',img)\n",
    "\n",
    "ret,thresh1 = cv2.threshold(img , 127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('Binary',thresh1)\n",
    "\n",
    "ret,thresh2 = cv2.threshold(img , 127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Binary Inverse',thresh2)\n",
    "\n",
    "ret,thresh3 = cv2.threshold(img , 127,255,cv2.THRESH_TRUNC)\n",
    "cv2.imshow('TRUNC',thresh3)\n",
    "\n",
    "ret,thresh4 = cv2.threshold(img , 127,255,cv2.THRESH_TOZERO)\n",
    "cv2.imshow('TOZERO',thresh4)\n",
    "\n",
    "ret,thresh5 = cv2.threshold(img , 127,255,cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('TOZERO Inverse',thresh5)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Thresholding & Otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/paper.jpg',0)\n",
    "cv2.imshow('Original',img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('Thresh Old Binary',thresh1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "img = cv2.GaussianBlur(img,(3,3),0)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY , 3 ,5)\n",
    "cv2.imshow(\"adaptive mean\",thresh)\n",
    "\n",
    "_,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Otsu\",th2)\n",
    "\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "_ , th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Gaussian Otsu\",th3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation - Erosion - Opening - Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input_.jpg',0)\n",
    "ret,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "img = cv2.blur(img,(3,3))\n",
    "\n",
    "cv2.imshow('Original',img)\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "erosion = cv2.erode(img,kernel,iterations=1)\n",
    "cv2.imshow('erosion',erosion)\n",
    "\n",
    "dilation = cv2.dilate(img,kernel,iterations=1)\n",
    "cv2.imshow('dilation',dilation)\n",
    "\n",
    "opening = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)\n",
    "cv2.imshow('opening',opening)\n",
    "\n",
    "closing = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)\n",
    "cv2.imshow('closing',closing)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection and Image Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input____.jpg',0)\n",
    "\n",
    "sobel_x = cv2.Sobel(img,cv2.CV_64F,0,1,ksize = 5)\n",
    "sobel_y = cv2.Sobel(img,cv2.CV_64F,1,0,ksize = 5)\n",
    "sobel_XorY = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "\n",
    "cv2.imshow('Original',img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('sobel_x',sobel_x)\n",
    "cv2.imshow('sobel_y',sobel_y)\n",
    "cv2.imshow('sobel_XorY',sobel_XorY)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "cv2.imshow('laplacian',laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(img,20,170)\n",
    "cv2.imshow('canny',canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PerspectiveTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input____.jpg')\n",
    "cv2.imshow('original',img)\n",
    "\n",
    "points_A = np.float32([ [50,15],[350,215],[85,350],[350,300] ])\n",
    "points_B = np.float32([[0,0],[420,0],[0,594],[420,594]])\n",
    "M = cv2.getPerspectiveTransform(points_A,points_B)\n",
    "warped = cv2.warpPerspective(img,M,(420,594))\n",
    "\n",
    "cv2.imshow('warped',warped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/input____.jpg')\n",
    "cv2.imshow('original',img)\n",
    "\n",
    "points_A = np.float32([ [50,15],[350,215],[85,350] ])\n",
    "points_B = np.float32([[0,0],[420,0],[0,594]])\n",
    "\n",
    "M = cv2.getAffineTransform(points_A,points_B)\n",
    "affined = cv2.warpAffine(img,M,(420,594))\n",
    "\n",
    "cv2.imshow('affined',affined)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project - Sketching on Live Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def sketch(img):\n",
    "    img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "    canny_edges = cv2.Canny(img_gray_blur,10,70) # 10 70\n",
    "    ret,mask = cv2.threshold(canny_edges , 70,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "    \n",
    "#cap = cv2.VideoCapture(0)\n",
    "image = cv2.imread('./images/input____.jpg')\n",
    "\n",
    "while True:\n",
    "    #ret,frame = cap.read()\n",
    "    cv2.imshow('Live Sketsh',sketch(image))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "#cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
